{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saish\\Anaconda2\\envs\\tf\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from tensorflow.contrib import learn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import cross_validation\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function will create batch of inputs with the following features \n",
    "#Maximum capacity of the queue is 10000 - which is maximum number of elements in the queue\n",
    "#Min elements in queue after every dequeue\n",
    "\n",
    "def inp_tensor_fn(dataset_split, batch_size, capacity=10000, min_after_dequeue=3000):\n",
    "    \n",
    "    def inp_fn():\n",
    "        img_batch, labels_batch = tf.train.shuffle_batch(\n",
    "            tensors = [dataset_split.images, dataset_split.labels.astype(np.int32)],\n",
    "            batch_size = batch_size,\n",
    "            capacity = capacity,\n",
    "            min_after_dequeue=min_after_dequeue,\n",
    "            enqueue_many=True,\n",
    "            num_threads=4)\n",
    "        features_map = {'images': img_batch}\n",
    "        return features_map, labels_batch\n",
    "    \n",
    "    return inp_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#This will load MNIST dataset and split it into train, test and validation\n",
    "#Train will contain 55k , validation will contain 5k and test will have 10k samples\n",
    "m_data = tf.contrib.learn.datasets.mnist.load_mnist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#convert image numpy arrays to tensor\n",
    "#input function will create mini batches of tensor\n",
    "#train data is divided into batchs of 256 whereas validation data is 5000 \n",
    "train_inp = inp_tensor_fn(m_data.train, batch_size=256)\n",
    "val_inp = inp_tensor_fn(m_data.validation, batch_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m_data = tf.contrib.learn.datasets.mnist.load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_set = tf.contrib.layers.real_valued_column('images', dimension=784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This optimizer supports FTRL Algo and has support for l2 regularization\n",
    "op = tf.train.FtrlOptimizer(learning_rate=50.0, l2_regularization_strength=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing RBF kernel Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_mapper = tf.contrib.kernel_methods.RandomFourierFeatureMapper(input_dim=784, output_dim=12000, stddev=5.0, name='rffm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp_map = {image_set: [kernel_mapper]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training & Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\saish\\AppData\\Local\\Temp\\tmpnx2k57_i\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001B5FADA0940>, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_environment': 'local', '_save_summary_steps': 100, '_num_ps_replicas': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_master': '', '_save_checkpoints_secs': 600, '_model_dir': 'C:\\\\Users\\\\saish\\\\AppData\\\\Local\\\\Temp\\\\tmpnx2k57_i', '_is_chief': True, '_num_worker_replicas': 0, '_save_checkpoints_steps': None, '_evaluation_master': '', '_task_type': None}\n"
     ]
    }
   ],
   "source": [
    "rbf = tf.contrib.kernel_methods.KernelLinearClassifier(n_classes=10, optimizer=op, kernel_mappers=inp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saish\\Anaconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\saish\\AppData\\Local\\Temp\\tmpnx2k57_i\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.30258, step = 1\n",
      "INFO:tensorflow:global_step/sec: 7.72235\n",
      "INFO:tensorflow:loss = 0.248888, step = 101 (12.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.6609\n",
      "INFO:tensorflow:loss = 0.163599, step = 201 (13.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.31904\n",
      "INFO:tensorflow:loss = 0.123285, step = 301 (14.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.12699\n",
      "INFO:tensorflow:loss = 0.100805, step = 401 (13.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.07709\n",
      "INFO:tensorflow:loss = 0.0698902, step = 501 (14.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.25857\n",
      "INFO:tensorflow:loss = 0.0893459, step = 601 (13.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.2526\n",
      "INFO:tensorflow:loss = 0.0700096, step = 701 (13.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.26903\n",
      "INFO:tensorflow:loss = 0.0881215, step = 801 (13.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.21359\n",
      "INFO:tensorflow:loss = 0.0594875, step = 901 (13.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.25029\n",
      "INFO:tensorflow:loss = 0.0585476, step = 1001 (13.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.14868\n",
      "INFO:tensorflow:loss = 0.0487103, step = 1101 (13.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.90366\n",
      "INFO:tensorflow:loss = 0.038632, step = 1201 (14.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.52205\n",
      "INFO:tensorflow:loss = 0.0412491, step = 1301 (15.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.031\n",
      "INFO:tensorflow:loss = 0.0409998, step = 1401 (14.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.31711\n",
      "INFO:tensorflow:loss = 0.0566759, step = 1501 (15.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.85764\n",
      "INFO:tensorflow:loss = 0.0619654, step = 1601 (14.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.49031\n",
      "INFO:tensorflow:loss = 0.0362202, step = 1701 (15.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.233\n",
      "INFO:tensorflow:loss = 0.0277704, step = 1801 (16.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.69542\n",
      "INFO:tensorflow:loss = 0.0245154, step = 1901 (14.936 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\saish\\AppData\\Local\\Temp\\tmpnx2k57_i\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0456349.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KernelLinearClassifier(params={'kernel_mappers': {_RealValuedColumn(column_name='images', dimension=784, default_value=None, dtype=tf.float32, normalizer=None): [<tensorflow.contrib.kernel_methods.python.mappers.random_fourier_features.RandomFourierFeatureMapper object at 0x000001B58310E400>]}, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x000001B58310E4E0>, 'optimizer': <tensorflow.python.training.ftrl.FtrlOptimizer object at 0x000001B58310E1D0>, 'feature_columns': {_RealValuedColumn(column_name='images_MAPPED', dimension=12000, default_value=None, dtype=tf.float32, normalizer=None)}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rbf.fit(input_fn=train_inp, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--NN fitting finished in  380193 ms--------------\n"
     ]
    }
   ],
   "source": [
    "end = int(round(time.time() * 1000))\n",
    "print(\"--NN fitting finished in \", (end-start), \"ms--------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation using evaluate method of kernelLinearClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saish\\Anaconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-11-21:10:48\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\saish\\AppData\\Local\\Temp\\tmpnx2k57_i\\model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-11-21:10:51\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.978, global_step = 2000, loss = 0.0780364\n",
      "{'accuracy': 0.97799999, 'loss': 0.07803645, 'global_step': 2000}\n"
     ]
    }
   ],
   "source": [
    "val = rbf.evaluate(input_fn=val_inp, steps=1)\n",
    "print (val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inp_tensor_fn1(dataset_split):\n",
    "    \n",
    "    def inp_fn1():\n",
    "        data_tf = tf.convert_to_tensor(dataset_split.images)\n",
    "        features_map = {'images': data_tf}\n",
    "        return features_map\n",
    "    \n",
    "    return inp_fn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_set = m_data.validation\n",
    "val_images = val_set.images\n",
    "val_labels = val_set.labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_pred = []\n",
    "for i in range(5000):\n",
    "    v_pred.append(val_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_inp = inp_tensor_fn1(m_data.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\saish\\AppData\\Local\\Temp\\tmpnx2k57_i\\model.ckpt-2000\n",
      "Test Accuracy 0.9802\n",
      "Test Recall 0.9802\n",
      "Test Precision 0.980230018318\n",
      "F1 0.980182190251\n",
      "Confusion Matrix [[476   1   0   1   0   0   0   1   0   0]\n",
      " [  0 561   0   0   1   0   0   1   0   0]\n",
      " [  2   5 471   1   2   0   1   2   4   0]\n",
      " [  0   0   4 479   0   3   1   3   2   1]\n",
      " [  0   1   1   0 529   0   1   1   0   2]\n",
      " [  0   1   2   5   1 424   1   0   0   0]\n",
      " [  2   1   2   0   1   1 493   0   1   0]\n",
      " [  1   1   2   0   2   1   0 540   1   2]\n",
      " [  0   2   1   5   0   4   1   0 449   0]\n",
      " [  2   2   0   3   1   0   1   6   1 479]]\n"
     ]
    }
   ],
   "source": [
    "v_pre = list(itertools.islice(rbf.predict(input_fn=val_inp),5000))\n",
    "v_classes = [p[\"classes\"] for p in v_pre]\n",
    "score = metrics.accuracy_score(v_pred, v_classes)\n",
    "print ('Test Accuracy', score)\n",
    "Recall = metrics.recall_score(v_pred, v_classes, average='weighted')\n",
    "print('Test Recall', Recall)\n",
    "Precision = metrics.precision_score(v_pred, v_classes, average='weighted')\n",
    "print('Test Precision', Precision)\n",
    "F1 = metrics.f1_score(v_pred, v_classes, average='weighted')\n",
    "print('F1', F1)\n",
    "matrix = metrics.confusion_matrix(v_pred, v_classes)\n",
    "print('Confusion Matrix', matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for RBF classifier KernelLinearClassifier(params={'kernel_mappers': {_RealValuedColumn(column_name='images', dimension=784, default_value=None, dtype=tf.float32, normalizer=None): [<tensorflow.contrib.kernel_methods.python.mappers.random_fourier_features.RandomFourierFeatureMapper object at 0x000001B58310E400>]}, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x000001B58310E4E0>, 'optimizer': <tensorflow.python.training.ftrl.FtrlOptimizer object at 0x000001B58310E1D0>, 'feature_columns': {_RealValuedColumn(column_name='images_MAPPED', dimension=12000, default_value=None, dtype=tf.float32, normalizer=None)}}):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       479\n",
      "          1       0.98      1.00      0.99       563\n",
      "          2       0.98      0.97      0.97       488\n",
      "          3       0.97      0.97      0.97       493\n",
      "          4       0.99      0.99      0.99       535\n",
      "          5       0.98      0.98      0.98       434\n",
      "          6       0.99      0.98      0.99       501\n",
      "          7       0.97      0.98      0.98       550\n",
      "          8       0.98      0.97      0.98       462\n",
      "          9       0.99      0.97      0.98       495\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for RBF classifier %s:\\n%s\\n\"\n",
    "     % (rbf, metrics.classification_report(v_pred, v_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inp_tensor_fn1(dataset_split):\n",
    "    \n",
    "    def inp_fn1():\n",
    "        data_tf = tf.convert_to_tensor(dataset_split.images)\n",
    "        features_map = {'images': data_tf}\n",
    "        print (features_map)\n",
    "        return features_map\n",
    "    \n",
    "    return inp_fn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = m_data.test\n",
    "test_images = test_set.images\n",
    "test_labels = test_set.labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = 10000\n",
    "pred = []\n",
    "for i in range(10000):\n",
    "    pred.append(test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_inp = inp_tensor_fn1(m_data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': <tf.Tensor 'Const:0' shape=(10000, 784) dtype=float32>}\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\saish\\AppData\\Local\\Temp\\tmpnx2k57_i\\model.ckpt-2000\n"
     ]
    }
   ],
   "source": [
    "pre = list(itertools.islice(rbf.predict(input_fn=test_inp),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_classes = [p[\"classes\"] for p in pre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.979\n",
      "Test Error 2.1\n",
      "Test Recall 0.979\n",
      "Test Precision 0.979013397511\n",
      "F1 0.97898836086\n",
      "Confusion Matrix [[ 973    0    0    1    0    2    1    1    2    0]\n",
      " [   0 1126    2    1    0    1    2    1    2    0]\n",
      " [   5    2 1006    2    2    1    0    6    8    0]\n",
      " [   0    0    2  993    0    5    0    3    5    2]\n",
      " [   0    0    4    0  961    0    3    1    1   12]\n",
      " [   2    0    0    7    2  875    3    1    1    1]\n",
      " [   6    2    0    1    4    7  936    1    1    0]\n",
      " [   1    8    8    1    0    1    0 1001    0    8]\n",
      " [   2    0    1    9    1    5    3    3  946    4]\n",
      " [   3    5    1    8    8    3    1    6    1  973]]\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(pred, predicted_classes)\n",
    "print ('Test Accuracy', score)\n",
    "Error = 100-round(metrics.accuracy_score(pred, predicted_classes)*100,2)\n",
    "print ('Test Error', Error)\n",
    "Recall = metrics.recall_score(pred, predicted_classes, average='weighted')\n",
    "print('Test Recall', Recall)\n",
    "Precision = metrics.precision_score(pred, predicted_classes, average='weighted')\n",
    "print('Test Precision', Precision)\n",
    "F1 = metrics.f1_score(pred, predicted_classes, average='weighted')\n",
    "print('F1', F1)\n",
    "matrix = metrics.confusion_matrix(pred, predicted_classes)\n",
    "print('Confusion Matrix', matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for RBF classifier KernelLinearClassifier(params={'kernel_mappers': {_RealValuedColumn(column_name='images', dimension=784, default_value=None, dtype=tf.float32, normalizer=None): [<tensorflow.contrib.kernel_methods.python.mappers.random_fourier_features.RandomFourierFeatureMapper object at 0x000001B58310E400>]}, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x000001B58310E4E0>, 'optimizer': <tensorflow.python.training.ftrl.FtrlOptimizer object at 0x000001B58310E1D0>, 'feature_columns': {_RealValuedColumn(column_name='images_MAPPED', dimension=12000, default_value=None, dtype=tf.float32, normalizer=None)}}):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.98      0.97      0.98      1032\n",
      "          3       0.97      0.98      0.98      1010\n",
      "          4       0.98      0.98      0.98       982\n",
      "          5       0.97      0.98      0.98       892\n",
      "          6       0.99      0.98      0.98       958\n",
      "          7       0.98      0.97      0.98      1028\n",
      "          8       0.98      0.97      0.97       974\n",
      "          9       0.97      0.96      0.97      1009\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for RBF classifier %s:\\n%s\\n\"\n",
    "     % (rbf, metrics.classification_report(pred, predicted_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
