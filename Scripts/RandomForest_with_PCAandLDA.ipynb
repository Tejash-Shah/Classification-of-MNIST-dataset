{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steja\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn import cross_validation\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "import time \n",
    "from sklearn import neighbors\n",
    "from sklearn.utils import shuffle\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata(\"MNIST original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(mnist.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = np.float32(mnist.data[:70000]), np.float32(mnist.target[:70000])\n",
    "X, y = shuffle(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X, y = np.float32(mnist.data[:70000]), np.float32(mnist.target[:70000])\n",
    "X_train, y_train = np.float32(X[:15000]), np.float32(y[:15000])\n",
    "X_test, y_test = np.float32(X[60000:]), np.float32(y[60000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance covered 1.0\n",
      "PCA Shape (15000, 700)\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(n_components=700)\n",
    "X_train_pca=pca.fit_transform(X_train,y_train)\n",
    "X_test_pca=pca.transform(X_test)\n",
    "print('Variance covered', pca.explained_variance_ratio_.sum())\n",
    "print('PCA Shape', X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steja\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance covered 1.0\n",
      "LDA Shape (15000, 9)\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "X_train_lda=lda.fit_transform(X_train_pca,y_train)\n",
    "X_test_lda=lda.transform(X_test_pca)\n",
    "print('Variance covered', lda.explained_variance_ratio_.sum())\n",
    "print('LDA Shape', X_train_lda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--NN fitting finished in  1258 ms--------------\n"
     ]
    }
   ],
   "source": [
    "start = int(round(time.time() * 1000))\n",
    "RF=RandomForestClassifier(random_state=1)\n",
    "RF.fit(X_train_lda,y_train)\n",
    "end = int(round(time.time() * 1000))\n",
    "print(\"--NN fitting finished in \", (end-start), \"ms--------------\")\n",
    "predicted=RF.predict(X_test_lda)\n",
    "expected=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90412783  0.90006662  0.90366667  0.90193462  0.8935247 ]\n"
     ]
    }
   ],
   "source": [
    "print(cross_validation.cross_val_score(RF, X_train_lda,y_train, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for kNN classifier RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=1, verbose=0, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.95      0.95       984\n",
      "        1.0       0.92      0.94      0.93      1107\n",
      "        2.0       0.83      0.87      0.85       959\n",
      "        3.0       0.83      0.85      0.84      1015\n",
      "        4.0       0.85      0.89      0.87       958\n",
      "        5.0       0.81      0.81      0.81       892\n",
      "        6.0       0.93      0.90      0.92      1025\n",
      "        7.0       0.88      0.88      0.88      1074\n",
      "        8.0       0.84      0.75      0.79      1009\n",
      "        9.0       0.84      0.82      0.83       977\n",
      "\n",
      "avg / total       0.87      0.87      0.87     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 939    0   14    4    3    4   11    1    7    1]\n",
      " [   1 1042   10    7    4    7    0    9   25    2]\n",
      " [   9   15  838   20   10    8   16   10   25    8]\n",
      " [   4    8   51  866    3   30    2   19   22   10]\n",
      " [   4    1   11    2  855    4   23    7    6   45]\n",
      " [  15    4   12   64    5  724   12    9   38    9]\n",
      " [  14    5   18    2   12   28  926    6   12    2]\n",
      " [   3   10   23   12   23    6    0  941    2   54]\n",
      " [   7   43   16   43   24   81    7    6  760   22]\n",
      " [   5    4   14   18   61    5    1   59   10  800]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for kNN classifier %s:\\n%s\\n\"\n",
    "     % (RF, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 86.91\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is:\",round(metrics.accuracy_score(expected,predicted)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error is: 13.09\n"
     ]
    }
   ],
   "source": [
    "print(\"Test error is:\",100-round(metrics.accuracy_score(expected,predicted)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 939    0   14    4    3    4   11    1    7    1]\n",
      " [   1 1042   10    7    4    7    0    9   25    2]\n",
      " [   9   15  838   20   10    8   16   10   25    8]\n",
      " [   4    8   51  866    3   30    2   19   22   10]\n",
      " [   4    1   11    2  855    4   23    7    6   45]\n",
      " [  15    4   12   64    5  724   12    9   38    9]\n",
      " [  14    5   18    2   12   28  926    6   12    2]\n",
      " [   3   10   23   12   23    6    0  941    2   54]\n",
      " [   7   43   16   43   24   81    7    6  760   22]\n",
      " [   5    4   14   18   61    5    1   59   10  800]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
